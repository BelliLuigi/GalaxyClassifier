{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c831bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "#from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cac3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyJungle(Dataset): # sarebbe interessante implementare un rescale/crop\n",
    "    \n",
    "    #the init function initializes the directory containing the image,\n",
    "    #the annotations file,\n",
    "    #and both transforms\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "\n",
    "    #returns number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return (self.img_labels).shape[0]\n",
    "\n",
    "    #loads a sample from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0])) + '.jpg'\n",
    "        #retrieves the image\n",
    "        image = Image.open(img_path)\n",
    "        if not is_rgb: image = image.convert('L')\n",
    "        #retrieves corresponding label\n",
    "        label = self.img_labels.iloc[idx, 1:]\n",
    "        #if possible, transform the image and the label into a tensor.\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label, self.img_labels.iloc[idx, 0]\n",
    "    \n",
    "\n",
    "transfs = transforms.Compose([\n",
    "    transforms.ToTensor(), #fa già la normalizzazione se l'immagine non è un tensore\n",
    "    # sarebbe interessante implementare un random crop prima del center crop per decentrare un poco le immagini????\n",
    "    transforms.RandomHorizontalFlip(), # horizontal flip\n",
    "    transforms.RandomVerticalFlip(), # vertical flip\n",
    "    transforms.CenterCrop(324)          #CROP\n",
    "    ]) #transforms.compose per fare una pipe di transformazioni\n",
    "\n",
    "\n",
    "\n",
    "DS = GalaxyJungle('../data/training/training_solutions_rev1.csv', '../data/training/', transfs)\n",
    "training, test = random_split(DS, [.8, .2])\n",
    "train_loader = DataLoader(training, batch_size=(batch_size_train := 128), shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test, batch_size=(batch_size_test := 128), shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d162ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyNet(nn.Module):\n",
    "    def __init__(self, n_conv_layers, num_filters,num_neurons1, num_neurons2):\n",
    "        super().__init__()\n",
    "        self.rgb = 1\n",
    "        self.input_size = 324\n",
    "        self.num_labels = 37\n",
    "        self.loss_dict = { 'batch' : [], 'epoch' : [], 'vbatch' : [], 'vepoch' : []}\n",
    "\n",
    "\n",
    "        stride = 2\n",
    "        kernel_size = 3\n",
    "        kernel_size_pool = 2\n",
    "        ## convolutional layers\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(self.rgb, num_filters[0], kernel_size=kernel_size)])\n",
    "        self.convs.append(nn.BatchNorm2d(num_filters[0]))\n",
    "        output_size = (self.input_size - kernel_size + stride) // (stride*kernel_size_pool)\n",
    "        for i in range(1,n_conv_layers):\n",
    "            self.convs.append(nn.Conv2d(num_filters[i-1], num_filters[i], kernel_size=kernel_size)) # num filters are the number of channel the conv layer otputs.\n",
    "            self.convs.append(nn.BatchNorm2d(num_filters[i]))\n",
    "            output_size = (output_size - kernel_size + stride) // (stride*kernel_size_pool) #padding 0, dilation = 1\n",
    "        self.pool = nn.MaxPool2d(kernel_size=kernel_size_pool)\n",
    "        #self.convs.append(nn.dropout(p= value)) ## to be added in the future to test claims of BatchnOrm paper\n",
    "        self.out_feature = num_filters[-1] *output_size * output_size # output size of the last conv layer\n",
    "        self.fc1 = nn.Linear(self.out_feature, num_neurons1) # fully connected layer\n",
    "        # dropout here if you want\n",
    "        self.fc2 = nn.Linear(num_neurons1, num_neurons2)\n",
    "        #dropout here if u want\n",
    "        self.fc3 = nn.Linear(num_neurons2, self.num_labels)\n",
    "\n",
    "    def init_weights(self,  mode, n_conv_layers):\n",
    "        if mode == 'relu': # perchè kaiming normal e non uniform??1\n",
    "            for i in range(0, n_conv_layers*2, 2):\n",
    "                nn.init.kaiming_normal_(self.convs[i].weight, nonlinearity=mode)\n",
    "                if self.convs[i].bias is not None:\n",
    "                    nn.init.constant_(self.convs[i].bias,0)\n",
    "            nn.init.kaiming_normal_(self.fc1.weight, nonlinearity=mode)\n",
    "            if self.fc1.bias is not None:\n",
    "                nn.init.constant_(self.fc1.bias,0)\n",
    "            nn.init.kaiming_normal_(self.fc2.weight, nonlinearity=mode)\n",
    "            if self.fc2.bias is not None:\n",
    "                nn.init.constant_(self.fc2.bias,0)\n",
    "        elif mode == 'leaky_relu':\n",
    "            for i in range(0, n_conv_layers*2, 2):\n",
    "                nn.init.kaiming_normal_(self.convs[i].weight, a = 0.01, nonlinearity=mode)\n",
    "                if self.convs[i].bias is not None:\n",
    "                    nn.init.constant_(self.convs[i].bias,0)\n",
    "            nn.init.kaiming_normal_(self.fc1.weight, nonlinearity=mode)\n",
    "            if self.fc1.bias is not None:\n",
    "                nn.init.constant_(self.fc1.bias,0)\n",
    "            nn.init.kaiming_normal_(self.fc2.weight, nonlinearity=mode)\n",
    "            if self.fc2.bias is not None:\n",
    "                nn.init.constant_(self.fc2.bias,0) \n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        if self.fc3.bias is not None:\n",
    "            nn.init.constant_(self.fc3.bias,0)\n",
    "        return print('weights initialized with {}'.format(mode))        \n",
    "        \n",
    "\n",
    "    def forward(self,x, activation):\n",
    "        for i in range(0, len(self.convs),2):\n",
    "            x = self.pool(activation(self.convs[i](x)))\n",
    "            x = self.convs[i+1](x) # batch norm layer\n",
    "        x = torch.flatten(x,1) # flatten operation -> 1 dimensional\n",
    "        x = activation(self.fc1(x)) # apply relu al'output dei fully connected\n",
    "        x = activation(self.fc2(x)) # idem sopra\n",
    "        x = F.linear(self.fc3(x)) # output di fc3, 37 neuroni -> 37 classi ideally \n",
    "        ## MAPPING ALSO HERE\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def set_rgb(self,bool):\n",
    "        if bool:\n",
    "            self.rgb = 3\n",
    "        else:\n",
    "            self.rgb = 1\n",
    "        return self.rgb\n",
    "    \n",
    "    def log_the_loss(self, item,epoch=False): # per avere una history della loss???\n",
    "        train = self.__getstate__()['training']\n",
    "        print(train)\n",
    "        if epoch and train:\n",
    "            self.loss_dict['epoch'].append(item) ### get state of the model so you can ditch the validation parameter\n",
    "        elif not epoch and train:\n",
    "            self.loss_dict['batch'].append(item)\n",
    "        elif not train and epoch:\n",
    "            self.loss_dict['vepoch'].append(item)\n",
    "        elif not train and not epoch:\n",
    "            self.loss_dict['vbatch'].append(item)\n",
    "        return item\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a06e03fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_conv_layers, num_filters,num_neurons1, num_neurons2):\n",
    "\n",
    "prova = GalaxyNet(2,[3,6,9],50, 45).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a44d75c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova.set_rgb(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357637a",
   "metadata": {},
   "source": [
    "## TRAINING + VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fad1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(prova.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aedbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_train(verbose=False):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "    prova.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs,labels, _ = data\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = prova(inputs, activation=F.relu)\n",
    "        loss=loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() # fa update del parameter\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galzoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
