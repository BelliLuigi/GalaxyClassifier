{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4297245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd967a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3de35",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Fine tuning dei parametri ---> optuna\n",
    "- Capire come salvare i dati [(documentazione)](https://docs.pytorch.org/tutorials/beginner/saving_loading_models.html) FATTO credo\n",
    "- mapping delle probabilità da aggiungere alla rete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c2c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change here if you want to use RGB images instead of grayscale\n",
    "is_rgb=False\n",
    "#Change here the size of the crop (original image is 424)\n",
    "csize=324 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d01e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyJungle(Dataset): # sarebbe interessante implementare un rescale/crop\n",
    "    \n",
    "    #the init function initializes the directory containing the image,\n",
    "    #the annotations file,\n",
    "    #and both transforms\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "\n",
    "    #returns number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return (self.img_labels).shape[0]\n",
    "\n",
    "    #loads a sample from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0])) + '.jpg'\n",
    "        #retrieves the image\n",
    "        image = Image.open(img_path)\n",
    "        if not is_rgb: image = image.convert('L')\n",
    "        #retrieves corresponding label\n",
    "        label = self.img_labels.iloc[idx, 1:]\n",
    "        #if possible, transform the image and the label into a tensor.\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label, self.img_labels.iloc[idx, 0]\n",
    "    \n",
    "\n",
    "transfs = transforms.Compose([\n",
    "    transforms.ToTensor(), #fa già la normalizzazione se l'immagine non è un tensore\n",
    "    #transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5]),  \n",
    "    transforms.CenterCrop(csize)          #CROP\n",
    "    ]) #transforms.compose per fare una pipe di transformazioni\n",
    "\n",
    "DS = GalaxyJungle('../data/training/training_solutions_rev1.csv', '../data/training/', transfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5513118",
   "metadata": {},
   "source": [
    "img, lab, indx = DS.__getitem__(0)\n",
    "#print(lab)\n",
    "#print(img)         #3D TENSOR    \n",
    "if is_rgb:\n",
    "    fig, ax = plt.subplots(1,3, figsize=(24,7))\n",
    "    color = ['Reds', 'Greens', 'Blues']\n",
    "    for i,j in enumerate(img):\n",
    "        ax[i].imshow(j, cmap=color[i])\n",
    "else:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(24,7))\n",
    "    ax.imshow(img[0], cmap='magma')\n",
    "#print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b19e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = random_split(DS, [.8, .2])\n",
    "train_loader = DataLoader(training, batch_size=128, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c51673",
   "metadata": {},
   "source": [
    "## NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d450aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENVIRONMENTAL VARIABLES\n",
    "if is_rgb: in_channels=3\n",
    "else: in_channels=1\n",
    "\n",
    "#change here for fine tuning\n",
    "kernel_size=5\n",
    "out_channels=6\n",
    "feature_map_2=16\n",
    "max_pool_kernel=2\n",
    "\n",
    "#for a 2 layer CNN:\n",
    "size1=((csize-kernel_size)/1) + 1 #first convolution\n",
    "size2=size1/max_pool_kernel       #first pooling\n",
    "size3=((size2-kernel_size)/1)+1   #second convolution\n",
    "size4=int(size3/max_pool_kernel)  #second pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0de85fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GalaxyNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=97344, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GalaxyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size) # convolutional layer # input 3 input channel, some output chans(feature maps) that are result from applying the kernel, also the kernel is trained during the process.\n",
    "        ## Operation:  ((424-5)/1) +1 (6,420,420)\n",
    "        self.pool = nn.MaxPool2d(max_pool_kernel,max_pool_kernel) #maxpool layer. divido per 2, -> (6,210,210)\n",
    "        self.conv2 = nn.Conv2d(out_channels,feature_map_2,kernel_size) # 210-5 +1 = 206 -> (16,206,206) # dopo qui si fa di nuovo il pooling per cui si arriva a (16,103,103)\n",
    "        self.fc1 = nn.Linear(feature_map_2*size4*size4,120) # fc è fully connected, #120 neuroni che prendono l'output\n",
    "        self.fc2 = nn.Linear(120,84)# un altro fc layer che prende dai 120 neuroni e connette a 84 neuroni\n",
    "        self.fc3 = nn.Linear(84,37)# idem sopra ma con 84 e 37 che è il numero di classi\n",
    "        #i numeri non vincolati sono il primo 6 e il primo 16 e poi i numeri di neuroni\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # step 1 in cui c'è prima convoluzione e primo poool\n",
    "        x = self.pool(F.relu(self.conv2(x))) # secondo step\n",
    "        x = torch.flatten(x,1) # flatten operation -> 1 dimensional\n",
    "        x = F.relu(self.fc1(x)) # apply relu al'output dei fully connected\n",
    "        x = F.relu(self.fc2(x)) # idem sopra\n",
    "        x = self.fc3(x) # output di fc3, 37 neuroni -> 37 classi ideally\n",
    "        return x\n",
    "    \n",
    "\n",
    "gnet = GalaxyNet().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0804377",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(gnet.parameters(), lr =0.001, momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b08b27d",
   "metadata": {},
   "source": [
    "In bianco e nero: 1 epoch 1m3s, loss 0.028\n",
    "\n",
    "Colori: 1 epoch 1m37s, loss 0.029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1f4bc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "[1,    20] loss: 0.286\n",
      "[1,    40] loss: 0.285\n",
      "[1,    60] loss: 0.286\n",
      "[1,    80] loss: 0.284\n",
      "[1,   100] loss: 0.283\n",
      "[1,   120] loss: 0.285\n",
      "[1,   140] loss: 0.285\n",
      "[1,   160] loss: 0.286\n",
      "[1,   180] loss: 0.286\n",
      "[1,   200] loss: 0.286\n",
      "[1,   220] loss: 0.286\n",
      "[1,   240] loss: 0.284\n",
      "[1,   260] loss: 0.285\n",
      "[1,   280] loss: 0.287\n",
      "[1,   300] loss: 0.284\n",
      "[1,   320] loss: 0.287\n",
      "[1,   340] loss: 0.286\n",
      "[1,   360] loss: 0.285\n",
      "[1,   380] loss: 0.285\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    print(f'Training epoch {epoch}')\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #type(data)\n",
    "        #print(data)\n",
    "        inputs, labels, idx = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # set gradients to ZERO\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = gnet(inputs) # whatever the net produces from inputs, at start completely wrong, then we compute loss \n",
    "        loss = loss_function(outputs, labels) # here we are! :) \n",
    "        loss.backward() # backpropagate the loss, \n",
    "        optimizer.step() # the nwe take a step using our optimizer\n",
    "\n",
    "        # print statistics\n",
    "        \n",
    "        running_loss +=np.sqrt(loss.item())  ## RMSE LOSS\n",
    "        if i % 20 == 19:    # print every 20 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bfb4192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore our model parameter so we don't have to retrain if we want to use it again\n",
    "now = datetime.now().strftime(\"%d-%m_%H-%M-%S\")\n",
    "model_last_name = f'gnet/trained_gnet_{now}.pth'\n",
    "torch.save({\n",
    "    'model_state_dict' : gnet.state_dict(), # tutti i pesi\n",
    "    'optimizer_state_dict' : optimizer.state_dict(), # values of the optimizer, loss is just the last loss value.\n",
    "    'loss' : loss}, model_last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ce07130",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnet = GalaxyNet()\n",
    "gnet.load_state_dict(torch.load(model_last_name)['model_state_dict'])\n",
    "optimizer.load_state_dict(torch.load(model_last_name)['optimizer_state_dict'])\n",
    "loss = torch.load(model_last_name)['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5394a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m         total += labels.size(\u001b[32m0\u001b[39m) \u001b[38;5;66;03m# 424 instances???\u001b[39;00m\n\u001b[32m     13\u001b[39m         \u001b[38;5;66;03m#correct += (predicted == labels).sum().item()\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#accuracy =  100*correct/total\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAccuracy : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation part\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "gnet.eval()\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(test_loader): ## da sostituire con il nostro test loader\n",
    "        images, labels, idx = data\n",
    "        outputs = gnet(images)\n",
    "        _, predicted = torch.max(outputs,1)\n",
    "        total += labels.size(0) # 424 instances???\n",
    "        #correct += (predicted == labels).sum().item()\n",
    "\n",
    "#accuracy =  100*correct/total\n",
    "#print(f'Accuracy : {accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galzoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
