{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4297245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3de35",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Fine tuning dei parametri ---> optuna\n",
    "- Capire come salvare i dati [(documentazione)](https://docs.pytorch.org/tutorials/beginner/saving_loading_models.html) FATTO credo\n",
    "- mapping delle probabilità da aggiungere alla rete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c2c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change here if you want to use RGB images instead of grayscale\n",
    "is_rgb=False\n",
    "#Change here the size of the crop (original image is 424)\n",
    "csize=324 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d01e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyJungle(Dataset): # sarebbe interessante implementare un rescale/crop\n",
    "    \n",
    "    #the init function initializes the directory containing the image,\n",
    "    #the annotations file,\n",
    "    #and both transforms\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "\n",
    "    #returns number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return (self.img_labels).shape[0]\n",
    "\n",
    "    #loads a sample from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0])) + '.jpg'\n",
    "        #retrieves the image\n",
    "        image = Image.open(img_path)\n",
    "        if not is_rgb: image = image.convert('L')\n",
    "        #retrieves corresponding label\n",
    "        label = self.img_labels.iloc[idx, 1:]\n",
    "        #if possible, transform the image and the label into a tensor.\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label, self.img_labels.iloc[idx, 0]\n",
    "    \n",
    "\n",
    "transfs = transforms.Compose([\n",
    "    transforms.ToTensor(), #fa già la normalizzazione se l'immagine non è un tensore\n",
    "    # sarebbe interessante implementare un random crop prima del center crop per decentrare un poco le immagini????\n",
    "    transforms.RandomHorizontalFlip(), # horizontal flip\n",
    "    transforms.RandomVerticalFlip(), # vertical flip\n",
    "    transforms.CenterCrop(csize)          #CROP\n",
    "    ]) #transforms.compose per fare una pipe di transformazioni\n",
    "\n",
    "\n",
    "\n",
    "DS = GalaxyJungle('../data/training/training_solutions_rev1.csv', '../data/training/', transfs)\n",
    "training, test = random_split(DS, [.8, .2])\n",
    "train_loader = DataLoader(training, batch_size=(batch_size_train := 128), shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test, batch_size=(batch_size_test := 128), shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5513118",
   "metadata": {},
   "source": [
    "img, lab, indx = DS.__getitem__(0)\n",
    "#print(lab)\n",
    "#print(img)         #3D TENSOR    \n",
    "if is_rgb:\n",
    "    fig, ax = plt.subplots(1,3, figsize=(24,7))\n",
    "    color = ['Reds', 'Greens', 'Blues']\n",
    "    for i,j in enumerate(img):\n",
    "        ax[i].imshow(j, cmap=color[i])\n",
    "else:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(24,7))\n",
    "    ax.imshow(img[0], cmap='magma')\n",
    "#print(img.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c51673",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d450aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENVIRONMENTAL VARIABLES\n",
    "if is_rgb: in_channels=3\n",
    "else: in_channels=1\n",
    "\n",
    "#change here for fine tuning\n",
    "kernel_size=5\n",
    "out_channels=6\n",
    "feature_map_2=16\n",
    "max_pool_kernel=2\n",
    "\n",
    "#for a 2 layer CNN:\n",
    "size1=((csize-kernel_size)/1) + 1 #first convolution\n",
    "size2=size1/max_pool_kernel       #first pooling\n",
    "size3=((size2-kernel_size)/1)+1   #second convolution\n",
    "size4=int(size3/max_pool_kernel)  #second pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de85fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size) # convolutional layer # input 3 input channel, some output chans(feature maps) that are result from applying the kernel, also the kernel is trained during the process.\n",
    "        ## Operation:  ((424-5)/1) +1 (6,420,420)\n",
    "        self.pool = nn.MaxPool2d(max_pool_kernel,max_pool_kernel) #maxpool layer. divido per 2, -> (6,210,210)\n",
    "        self.conv2 = nn.Conv2d(out_channels,feature_map_2,kernel_size) # 210-5 +1 = 206 -> (16,206,206) # dopo qui si fa di nuovo il pooling per cui si arriva a (16,103,103)\n",
    "        self.fc1 = nn.Linear(feature_map_2*size4*size4,120) # fc è fully connected, #120 neuroni che prendono l'output\n",
    "        self.fc2 = nn.Linear(120,84)# un altro fc layer che prende dai 120 neuroni e connette a 84 neuroni\n",
    "        self.fc3 = nn.Linear(84,37)# idem sopra ma con 84 e 37 che è il numero di classi\n",
    "        #i numeri non vincolati sono il primo 6 e il primo 16 e poi i numeri di neuroni\n",
    "        ## Instance variables:\n",
    "        self.loss_dict = { 'batch' : [], 'epoch' : [], 'vbatch' : [], 'vepoch' : []}\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # step 1 in cui c'è prima convoluzione e primo poool\n",
    "        x = self.pool(F.relu(self.conv2(x))) # secondo step\n",
    "        x = torch.flatten(x,1) # flatten operation -> 1 dimensional\n",
    "        x = F.relu(self.fc1(x)) # apply relu al'output dei fully connected\n",
    "        x = F.relu(self.fc2(x)) # idem sopra\n",
    "        x = self.fc3(x) # output di fc3, 37 neuroni -> 37 classi ideally\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def log_the_loss(self, item,epoch=False): # per avere una history della loss???\n",
    "        train = gnet.__getstate__()['training']\n",
    "        if epoch and train:\n",
    "            self.loss_dict['epoch'].append(item) ### get state of the model so you can ditch the validation parameter\n",
    "        elif not epoch and train:\n",
    "            self.loss_dict['batch'].append(item)\n",
    "        elif not train and epoch:\n",
    "            self.loss_dict['vepoch'].append(item)\n",
    "        elif not train and not epoch:\n",
    "            self.loss_dict['vbatch'].append(item)\n",
    "        return item\n",
    "    \n",
    "\n",
    "gnet = GalaxyNet().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0804377",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(gnet.parameters(), lr =0.001, momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b08b27d",
   "metadata": {},
   "source": [
    "In bianco e nero: 1 epoch 1m3s, loss 0.028\n",
    "\n",
    "Colori: 1 epoch 1m37s, loss 0.029"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead02e1",
   "metadata": {},
   "source": [
    "## Traininig + validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04322d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_train(verbose=False):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    gnet.train(True)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels, idx = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = gnet(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        RMSEloss =  np.sqrt(loss.item())\n",
    "        if verbose and i%10==0: print(f'Batch {i+1}/{len(train_loader)} - Loss: {RMSEloss:.3f}')\n",
    "        running_loss += RMSEloss\n",
    "        gnet.log_the_loss(RMSEloss, epoch=False, validation=False)\n",
    "        if i == len(train_loader)-1:\n",
    "            epochmean_loss = running_loss / len(train_loader)\n",
    "            if verbose: print(f\"---\\nEpoch {epoch} - Loss: {epochmean_loss:.3f}\\n---\")\n",
    "            gnet.log_the_loss(epochmean_loss, epoch=True, validation=False)\n",
    "            last_loss = RMSEloss\n",
    "            if verbose: print(f\"---\\nEpoch {epoch} - Loss: {last_loss:.3f}\\n---\")\n",
    "    return last_loss\n",
    "\n",
    "def one_epoch_eval(verbose=False):\n",
    "    gnet.eval()\n",
    "    running_validation_loss = 0.\n",
    "    if verbose: print('Evaluation...')\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(test_loader):\n",
    "            inputs, labels, idx = vdata\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = gnet(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            RMSEloss =  np.sqrt(loss.item())\n",
    "            running_validation_loss += RMSEloss\n",
    "            gnet.log_the_loss(RMSEloss,epoch=False, validation = True)\n",
    "    mean_vloss = gnet.log_the_loss(RMSEloss/(i+1), epoch=True, validation=True)\n",
    "    if verbose: print(f\"---\\nValidation Loss: {mean_vloss:.3f}\\n---\")\n",
    "    return mean_vloss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c6f70d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "Batch 1/385 - Loss: 0.280\n",
      "Batch 11/385 - Loss: 0.287\n",
      "Batch 21/385 - Loss: 0.270\n",
      "Batch 31/385 - Loss: 0.278\n",
      "Batch 41/385 - Loss: 0.284\n",
      "Batch 51/385 - Loss: 0.291\n",
      "Batch 61/385 - Loss: 0.273\n",
      "Batch 71/385 - Loss: 0.280\n",
      "Batch 81/385 - Loss: 0.280\n",
      "Batch 91/385 - Loss: 0.277\n",
      "Batch 101/385 - Loss: 0.285\n",
      "Batch 111/385 - Loss: 0.287\n",
      "Batch 121/385 - Loss: 0.272\n",
      "Batch 131/385 - Loss: 0.283\n",
      "Batch 141/385 - Loss: 0.284\n",
      "Batch 151/385 - Loss: 0.283\n",
      "Batch 161/385 - Loss: 0.283\n",
      "Batch 171/385 - Loss: 0.287\n",
      "Batch 181/385 - Loss: 0.289\n",
      "Batch 191/385 - Loss: 0.284\n",
      "Batch 201/385 - Loss: 0.281\n",
      "Batch 211/385 - Loss: 0.279\n",
      "Batch 221/385 - Loss: 0.284\n",
      "Batch 231/385 - Loss: 0.279\n",
      "Batch 241/385 - Loss: 0.284\n",
      "Batch 251/385 - Loss: 0.271\n",
      "Batch 261/385 - Loss: 0.284\n",
      "Batch 271/385 - Loss: 0.279\n",
      "Batch 281/385 - Loss: 0.274\n",
      "Batch 291/385 - Loss: 0.269\n",
      "Batch 301/385 - Loss: 0.278\n",
      "Batch 311/385 - Loss: 0.278\n",
      "Batch 321/385 - Loss: 0.280\n",
      "Batch 331/385 - Loss: 0.272\n",
      "Batch 341/385 - Loss: 0.276\n",
      "Batch 351/385 - Loss: 0.273\n",
      "Batch 361/385 - Loss: 0.272\n",
      "Batch 371/385 - Loss: 0.281\n",
      "Batch 381/385 - Loss: 0.281\n",
      "---\n",
      "Epoch 0 - Loss: 0.279\n",
      "---\n",
      "---\n",
      "Epoch 0 - Loss: 0.000\n",
      "---\n",
      "Evaluation...\n",
      "---\n",
      "Validation Loss: 0.003\n",
      "---\n",
      "Training epoch 1\n",
      "Batch 1/385 - Loss: 0.276\n",
      "Batch 11/385 - Loss: 0.283\n",
      "Batch 21/385 - Loss: 0.279\n",
      "Batch 31/385 - Loss: 0.280\n",
      "Batch 41/385 - Loss: 0.275\n",
      "Batch 51/385 - Loss: 0.272\n",
      "Batch 61/385 - Loss: 0.274\n",
      "Batch 71/385 - Loss: 0.284\n",
      "Batch 81/385 - Loss: 0.281\n",
      "Batch 91/385 - Loss: 0.286\n",
      "Batch 101/385 - Loss: 0.278\n",
      "Batch 111/385 - Loss: 0.281\n",
      "Batch 121/385 - Loss: 0.274\n",
      "Batch 131/385 - Loss: 0.271\n",
      "Batch 141/385 - Loss: 0.282\n",
      "Batch 151/385 - Loss: 0.281\n",
      "Batch 161/385 - Loss: 0.280\n",
      "Batch 171/385 - Loss: 0.272\n",
      "Batch 181/385 - Loss: 0.278\n",
      "Batch 191/385 - Loss: 0.275\n",
      "Batch 201/385 - Loss: 0.284\n",
      "Batch 211/385 - Loss: 0.281\n",
      "Batch 221/385 - Loss: 0.275\n",
      "Batch 231/385 - Loss: 0.284\n",
      "Batch 241/385 - Loss: 0.277\n",
      "Batch 251/385 - Loss: 0.278\n",
      "Batch 261/385 - Loss: 0.287\n",
      "Batch 271/385 - Loss: 0.273\n",
      "Batch 281/385 - Loss: 0.283\n",
      "Batch 291/385 - Loss: 0.284\n",
      "Batch 301/385 - Loss: 0.279\n",
      "Batch 311/385 - Loss: 0.280\n",
      "Batch 321/385 - Loss: 0.282\n",
      "Batch 331/385 - Loss: 0.276\n",
      "Batch 341/385 - Loss: 0.282\n",
      "Batch 351/385 - Loss: 0.281\n",
      "Batch 361/385 - Loss: 0.284\n",
      "Batch 371/385 - Loss: 0.280\n",
      "Batch 381/385 - Loss: 0.279\n",
      "---\n",
      "Epoch 1 - Loss: 0.279\n",
      "---\n",
      "---\n",
      "Epoch 1 - Loss: 0.000\n",
      "---\n",
      "Evaluation...\n",
      "---\n",
      "Validation Loss: 0.003\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,2):\n",
    "    print(f'Training epoch {epoch}')\n",
    "    epoch_last_loss = one_epoch_train(verbose=True)\n",
    "    #print(f'Epoch {epoch} - Loss: {epoch_last_loss:.3f}')\n",
    "    epoch_vloss = one_epoch_eval(verbose=True)\n",
    "    #print(f'Epoch {epoch} - Validation Loss: {epoch_vloss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d7d13",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfb4192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore our model parameter so we don't have to retrain if we want to use it again\n",
    "now = datetime.now().strftime(\"%d-%m_%H-%M-%S\")\n",
    "model_last_name = f'gnet/trained_gnet_{now}.pth'\n",
    "torch.save({\n",
    "    'model_state_dict' : gnet.state_dict(), # tutti i pesi\n",
    "    'optimizer_state_dict' : optimizer.state_dict(), # values of the optimizer, loss is just the last loss value.\n",
    "    'loss' : gnet.loss_dict,\n",
    "    'batchsize_train_test' : (batch_size_train, batch_size_test),\n",
    "    'device' : device,\n",
    "    'is_rgb' : is_rgb,\n",
    "    'crop_size' : csize,\n",
    "    'kernel_size' : kernel_size,\n",
    "    'out_channels' : out_channels,\n",
    "    'feature_map_2' : feature_map_2,\n",
    "    'max_pool_kernel' : max_pool_kernel,\n",
    "    'loss_function' : str(loss_function),\n",
    "    'optimizer' : str(optimizer),\n",
    "    'epoch' : len(gnet.loss_dict['epoch'])}, model_last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d0ef3",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce07130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnet = GalaxyNet()\n",
    "gnet.load_state_dict(torch.load(model_last_name)['model_state_dict'])\n",
    "optimizer.load_state_dict(torch.load(model_last_name)['optimizer_state_dict'])\n",
    "loss = torch.load(model_last_name)['loss']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfff322",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3449955012.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef objective(trial):\u001b[39m\n                         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    model = GalaxyNet().to(device)\n",
    "    optimizer_ optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    train_loader, valid_loader = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galzoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
